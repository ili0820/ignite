name: Run HVD-specific unit tests on GPUs
on:
  push:
    paths:
      - "ignite/**"
      - "tests/ignite/**"
      - "tests/run_gpu_tests.sh"
      - "tests/run_code_style.sh"
      - "examples/**.py"
      - "requirements-dev.txt"
      - ".github/workflows/gpu-hvd-tests.yml"
  workflow_dispatch:

concurrency:
  # <workflow_name>-<branch_name>-<true || commit_sha (if branch is protected)>
  group: gpu-hvd-tests-${{ github.ref_name }}-${{ !(github.ref_protected) || github.sha }}
  cancel-in-progress: true

jobs:
  gpu-hvd-tests:
    runs-on: [self-hosted, 2-gpus]
    defaults:
      run:
        shell: bash
    strategy:
      max-parallel: 1
      fail-fast: true

    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - name: Get year & week number
        id: get-date
        run: |
          echo "date=$(/bin/date "+%Y-%U")" >> $GITHUB_OUTPUT

      - name: Get pip cache dir
        id: pip-cache
        run: |
          pip install -U pip || python -m pip install -U pip
          echo "pip_cache=$(pip cache dir)" >> $GITHUB_OUTPUT

      - uses: actions/cache@v3
        with:
          path: |
            ${{ steps.pip-cache.outputs.pip_cache }}
          key: ${{ steps.get-date.outputs.date }}-pytorch-${{ runner.os }}-3.8-pytorch-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ steps.get-date.outputs.date }}-pytorch-${{ runner.os }}--3.8-pytorch-

      - run: pip install pip wheel setuptools -Uqq

      - name: Install PyTorch
        # https://pytorch.org/get-started/locally/
        run: |
# <<<<<<< HEAD
#           pip install --upgrade torch torchvision --extra-index-url https://download.pytorch.org/whl/cu117
# =======
#           pip install torch torchvision -f https://download.pytorch.org/whl/cu116/torch_stable.html
# >>>>>>> a670b8620 (Update gpu-hvd-tests.yml)
          nvidia-smi
# <<<<<<< HEAD
#           python -c "import torch; print(torch.__version__, ', CUDA is available: ', torch.cuda.is_available()); exit(not torch.cuda.is_available())"
# =======
#           python -c "import torch; print('CUDA is available: ', torch.cuda.is_available())"
# >>>>>>> 7174b733d (Update gpu-hvd-tests.yml)

      - name: Install Horovod with NCCL GPU ops
        run: |
# <<<<<<< HEAD
# # <<<<<<< HEAD
# #           HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_PYTORCH=1 pip install horovod[pytorch]
# # =======
# #           cd $GITHUB_WORKSPACE/horovod && python setup.py sdist
# #           conda install -y cmake nccl cuda-nvcc -c nvidia
# #           cd $GITHUB_WORKSPACE/horovod && HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_NCCL_LINK=SHARED HOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_PYTORCH=1 pip install -v $(ls $GITHUB_WORKSPACE/horovod/dist/horovod-*.tar.gz) && ldconfig
# # >>>>>>> a670b8620 (Update gpu-hvd-tests.yml)
# =======
#           HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_WITH_PYTORCH=1 pip install horovod[pytorch] --no-cache-dir
# >>>>>>> 7174b733d (Update gpu-hvd-tests.yml)
          horovodrun --check-build

      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt
          python setup.py install

      - name: Run GPU/CPU Unit Tests
        run: |
          bash tests/run_gpu_tests.sh 2 hvd

          CUDA_VISIBLE_DEVICES="" pytest --cov ignite --cov-append --cov-report term-missing --cov-report xml -vvv tests/ -m distributed -k hvd

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: gpu-2
          fail_ci_if_error: false

      - name: Install additional example dependencies
        run: pip install fire

      - name: Check CIFAR10 using horovodrun
        run: |
          export example_path="examples/contrib/cifar10"
          # initial run
          export stop_cmd="--stop_iteration=500"
          CI=1 horovodrun -np 2 python -u ${example_path}/main.py run --backend=horovod --checkpoint_every=200
          # resume
          export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-horovod-2_stop-on-500/training_checkpoint_400.pt"
          CI=1 horovodrun -np 2 python ${example_path}/main.py run --checkpoint_every=200 --num_epochs=7 ${resume_opt}

      - name: Check CIFAR10 using spawn
        run: |
          export example_path="examples/contrib/cifar10"
          # initial run
          export stop_cmd="--stop_iteration=500"
          CI=1 python -u ${example_path}/main.py run --backend=horovod --nproc_per_node=2 --checkpoint_every=200 ${stop_cmd}
          # resume
          export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-horovod-2_stop-on-500/training_checkpoint_400.pt"
          CI=1 python -u ${example_path}/main.py run --backend=horovod --nproc_per_node=2 --checkpoint_every=200 --num_epochs=7 ${resume_opt}
